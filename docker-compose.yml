version: '3.8'

x-kafka-common: &kafka-common
    image: confluentinc/cp-kafka:7.6.5
    networks:
        - stream-net
    environment: &kafka-common-env
        KAFKA_PROCESS_ROLES: broker,controller
        KAFKA_CONTROLLER_QUORUM_VOTERS: "0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093"
        CLUSTER_ID: "2qVoY3q1Q5O5hH1XVvqLmg"
        KAFKA_LISTENERS: "CONTROLLER://:9093,INTERNAL://:29092,DOCKER://:9092,EXTERNAL://0.0.0.0:9094"
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,DOCKER:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"
        KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
        KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
        KAFKA_AUTO_CREATE_TOPICS_ENABLED: "true"
        KAFKA_NUM_PARTITIONS: 3
        KAFKA_SASL_ENABLED_MECHANISMS: "PLAIN"
        KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: "PLAIN"
        KAFKA_OPTS: >
            -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf
            -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar=9091:/opt/jmx_exporter/kafka-metrics.yml

services:
    kafka-0:
        <<: *kafka-common
        container_name: kafka-0
        hostname: kafka-0
        volumes:
            - kafka-data-0:/var/lib/kafka/data
            - ./kafka/config/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf
            - ./monitoring/jmx-exporter/configs/kafka-metrics.yml:/opt/jmx_exporter/kafka-metrics.yml:ro
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar:ro
        ports:
            - "9094:9094"
            - "9092:9092"
        environment:
            <<: *kafka-common-env
            KAFKA_NODE_ID: 0
            KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka-0:29092,DOCKER://kafka-0:9092,EXTERNAL://localhost:9094"

    kafka-1:
        <<: *kafka-common
        container_name: kafka-1
        hostname: kafka-1
        volumes:
            - kafka-data-1:/var/lib/kafka/data
            - ./kafka/config/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf
            - ./monitoring/jmx-exporter/configs/kafka-metrics.yml:/opt/jmx_exporter/kafka-metrics.yml:ro
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar:ro
        ports:
            - "9095:9094"
            - "9192:9092"
        environment:
            <<: *kafka-common-env
            KAFKA_NODE_ID: 1
            KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka-1:29092,DOCKER://kafka-1:9092,EXTERNAL://localhost:9095"

    kafka-2:
        <<: *kafka-common
        container_name: kafka-2
        hostname: kafka-2
        volumes:
            - kafka-data-2:/var/lib/kafka/data
            - ./kafka/config/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf
            - ./monitoring/jmx-exporter/configs/kafka-metrics.yml:/opt/jmx_exporter/kafka-metrics.yml:ro
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar:ro
        ports:
            - "9096:9094"
            - "9292:9092"
        environment:
            <<: *kafka-common-env
            KAFKA_NODE_ID: 2
            KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka-2:29092,DOCKER://kafka-2:9092,EXTERNAL://localhost:9096"

    akhq:
        image: tchiotludo/akhq:0.25.1
        container_name: akhq
        ports:
            - "8080:8080"
        networks:
            - stream-net
        environment:
            AKHQ_CONFIGURATION: |+
                akhq:
                    connections:
                        kafka-server:
                            properties:
                                bootstrap.servers: "kafka-0:9092,kafka-1:9092,kafka-2:9092"
                                security.protocol: SASL_PLAINTEXT
                                sasl.mechanism: PLAIN
                                sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="kafka" password="admin";
                    security:
                        default-group: no-roles
                        basic-auth:
                            -   username: admin
                                password: "8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918"
                                passwordHash: SHA256
                                groups:
                                    - admin
                micronaut:
                    security:
                        enabled: true
                        token:
                            jwt:
                                signatures:
                                    secret:
                                        generator:
                                            secret: "6661a0975cd371c713f66a94bcd51ec874e0b040aec61f025964ad5fe7ee3120"

                                        
    spark-master:
        build:
            context: ./spark
            dockerfile: Dockerfile
        container_name: spark-master
        command: bin/spark-class org.apache.spark.deploy.master.Master
        ports:
            - "7077:7077"
            - "8081:8080"
            - "4040:4040"
        environment:
            SPARK_MODE: master
            SPARK_USER: spark
            SPARK_MASTER_OPTS: >
                -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar=5556:/opt/jmx_exporter/config.yaml -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
        volumes:
            - spark_data:/data
            - ./spark/main:/opt/bitnami/spark/main
            - ./spark/compressed_spark_jobs:/opt/bitnami/spark/compressed_jobs
            - ./monitoring/jmx-exporter/configs/spark-metrics.yaml:/opt/jmx_exporter/config.yaml
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar
        networks:
            - stream-net

    spark-worker-1:
        build:
            context: ./spark
            dockerfile: Dockerfile
        container_name: spark-worker-1
        command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_USER=spark
            - SPARK_MASTER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
            - SPARK_DAEMON_JAVA_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
        depends_on:
            - spark-master
        volumes:
            - spark_data:/data
            - ./spark/main:/opt/bitnami/spark/main
            - ./spark/compressed_spark_jobs:/opt/bitnami/spark/compressed_jobs
            - ./monitoring/jmx-exporter/configs/spark-metrics.yaml:/opt/jmx_exporter/config.yaml
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar
        networks:
            - stream-net

    spark-worker-2:
        build:
            context: ./spark
            dockerfile: Dockerfile
        container_name: spark-worker-2
        command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_USER=spark
            - SPARK_MASTER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
            - SPARK_DAEMON_JAVA_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
        depends_on:
            - spark-master
        volumes:
            - spark_data:/data
            - ./spark/main:/opt/bitnami/spark/main
            - ./spark/compressed_spark_jobs:/opt/bitnami/spark/compressed_jobs
            - ./monitoring/jmx-exporter/configs/spark-metrics.yaml:/opt/jmx_exporter/config.yaml
            - ./monitoring/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar:/opt/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar
        networks:
            - stream-net

    airflow-data:
        image: postgres:16
        container_name: airflow-data
        hostname: airflow-data
        environment:
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres
            - POSTGRES_DB=airflow
        healthcheck:
            test: [ "CMD-SHELL", "pg_isready -U postgres" ]
            interval: 10s
            timeout: 5s
            retries: 5
        volumes:
            - airflow_data:/var/lib/postgresql/data
        networks:
            - stream-net

    airflow-init:
        build:
            context: ./airflow
            dockerfile: Dockerfile
        volumes:
            - ./airflow/dags:/opt/airflow/dags
            - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
        container_name: airflow-init
        entrypoint: /bin/bash
        command: >
            -c 'airflow db init &&
                airflow users create \
                --role Admin \
                --username airflow \
                --password airflow \
                --email airflow@airflow.com \
                --firstname airflow \
                --lastname airflow;'
        depends_on:
            airflow-data:
                condition: service_healthy
        restart: on-failure
        networks:
            - stream-net

    airflow-webserver:
        build:
            context: ./airflow
            dockerfile: Dockerfile
        volumes:
            - ./airflow/dags:/opt/airflow/dags
            - ./airflow/plugins:/opt/airflow/plugins
            - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
        container_name: airflow-webserver
        command: airflow webserver
        ports:
            - "8082:8080"
        restart: unless-stopped
        depends_on:
            - airflow-init
        networks:
            - stream-net

    airflow-scheduler:
        build:
            context: ./airflow
            dockerfile: Dockerfile
        volumes:
            - ./airflow/dags:/opt/airflow/dags
            - ./airflow/plugins:/opt/airflow/plugins
            - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
        container_name: airflow-scheduler
        command: airflow scheduler
        restart: unless-stopped
        depends_on:
            - airflow-init
        networks:
            - stream-net

    postgres:
        image: postgres:16
        hostname: postgres-data
        environment:
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres
            - POSTGRES_DB=glamira
        ports:
            - "5432:5432"
        healthcheck:
            test: [ "CMD-SHELL", "pg_isready -U postgres" ]
            interval: 10s
            timeout: 5s
            retries: 5
        volumes:
            - postgres_data:/var/lib/postgresql/data
            - ./postgres/initdb:/docker-entrypoint-initdb.d
        networks:
            - stream-net
    pgadmin:
        image: dpage/pgadmin4
        environment:
            - PGADMIN_DEFAULT_EMAIL=postgresql@test.com
            - PGADMIN_DEFAULT_PASSWORD=postgresql
        ports:
            - "8085:80"
        networks:
            - stream-net

    prometheus:
        image: prom/prometheus:latest
        ports:
            - "9090:9090"
        volumes:
            - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
            - prometheus_data:/prometheus
        networks:
            - stream-net

    grafana:
        image: grafana/grafana:latest
        ports:
            - "3000:3000"
        volumes:
            - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
            - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
            - grafana_data:/var/lib/grafana
        environment:
            GF_SECURITY_ADMIN_USER: admin
            GF_SECURITY_ADMIN_PASSWORD: admin
        networks:
            - stream-net
    
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
        environment:
        - discovery.type=single-node
        - xpack.security.enabled=false
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        ports:
        - "9200:9200"
        - "9300:9300"
        volumes:
        - elasticsearch_data:/usr/share/elasticsearch/data
        - ./monitoring/elasticsearch/elasticsearch.yml:/usr/share/config/elasticsearch.yml
        networks:
            - stream-net
    
    kibana:
        image: docker.elastic.co/kibana/kibana:8.10.2
        environment:
        - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
        - SERVER_HOST=0.0.0.0
        - XPACK_SECURITY_ENABLED=false
        ports:
        - "5601:5601"
        depends_on:
        - elasticsearch
        networks:
            - stream-net
    logstash:
        image: docker.elastic.co/logstash/logstash:8.10.2
        volumes:
        - ./monitoring/logstash/config:/usr/share/logstash/config:ro
        - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
        ports:
        - "5044:5044"
        - "9600:9600"
        environment:
        - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
        depends_on:
        - elasticsearch
        networks:
            - stream-net
# filebeat:
#     image: docker.elastic.co/beats/filebeat:8.10.2
#     user: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
#     volumes:
#         - ./monitoring/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
#         - ./monitoring/filebeat/logs:/usr/share/filebeat/logs:ro
#     networks:
#         - stream-net


# postgres-exporter:
#     image: prometheuscommunity/postgres-exporter
#     environment:
#         DATA_SOURCE_NAME: "postgresql://postgres:postgres@postgres-data:5432/glamira?sslmode=disable"
#         PG_EXPORTER_WEB_LISTEN_ADDRESS: ":9187"
#     ports:
#     - "9187:9187"
#     depends_on:
#         - postgres
#     networks:
#         - stream-net



networks:
    stream-net:
        driver: bridge
        attachable: true

volumes:
    kafka-data-0:
    kafka-data-1:
    kafka-data-2:
    spark_data:
    airflow_data:
    postgres_data:
    prometheus_data:
    grafana_data:
    elasticsearch_data:
